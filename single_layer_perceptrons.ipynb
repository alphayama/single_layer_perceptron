{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Layer Perceptron\n",
    "\n",
    "<!--### Introduction-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data as Pandas DataFrame\n",
    "\n",
    "iris-setosa: -1\n",
    "\n",
    "iris-versicolor: 0\n",
    "\n",
    "iris-virginica: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal_len_cm</th>\n      <th>Sepal_wid_cm</th>\n      <th>Petal_len_cm</th>\n      <th>Petal_wid_cm</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.4</td>\n      <td>3.9</td>\n      <td>1.7</td>\n      <td>0.4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4.6</td>\n      <td>3.4</td>\n      <td>1.4</td>\n      <td>0.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5.0</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4.4</td>\n      <td>2.9</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>5.4</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   Sepal_len_cm  Sepal_wid_cm  Petal_len_cm  Petal_wid_cm  Type\n0           4.9           3.0           1.4           0.2     0\n1           4.7           3.2           1.3           0.2     0\n2           4.6           3.1           1.5           0.2     0\n3           5.0           3.6           1.4           0.2     0\n4           5.4           3.9           1.7           0.4     0\n5           4.6           3.4           1.4           0.3     0\n6           5.0           3.4           1.5           0.2     0\n7           4.4           2.9           1.4           0.2     0\n8           4.9           3.1           1.5           0.1     0\n9           5.4           3.7           1.5           0.2     0"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('iris.csv')\n",
    "data.columns=['Sepal_len_cm','Sepal_wid_cm','Petal_len_cm','Petal_wid_cm','Type']\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "- I am using Sigmoid function as the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_func(value):    #Tangent Hypotenuse\n",
    "    #return (1/(1+np.exp(-value)))\n",
    "    return ((np.exp(value)-np.exp(-value))/(np.exp(value)+np.exp(-value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_train(in_data,labels,alpha):\n",
    "    X=np.array(in_data)\n",
    "    y=np.array(labels)\n",
    "    weights=np.random.random(X.shape[1])\n",
    "    original=weights\n",
    "    bias=np.random.random_sample()\n",
    "    for key in range(X.shape[0]):\n",
    "        a=activation_func(np.matmul(np.transpose(weights),X[key]))     \n",
    "        yn=0\n",
    "        if a>=0.7:\n",
    "            yn=1\n",
    "        elif a<=(-0.7):\n",
    "            yn=-1\n",
    "        weights=weights+alpha*(yn-y[key])*X[key]\n",
    "        print('Iteration '+str(key)+': '+str(weights))\n",
    "    print('Difference: '+str(weights-original))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_test(in_data,label_shape,weights):\n",
    "    X=np.array(in_data)\n",
    "    y=np.zeros(label_shape)\n",
    "    for key in range(X.shape[1]):\n",
    "        a=activation_func((weights*X[key]).sum())\n",
    "        y[key]=0\n",
    "        if a>=0.7:\n",
    "            y[key]=1\n",
    "        elif a<=(-0.7):\n",
    "            y[key]=-1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(result,labels):\n",
    "    difference=result-np.array(labels)                                                        \n",
    "    correct_ctr=0\n",
    "    for elem in range(difference.shape[0]):\n",
    "        if difference[elem]==0:\n",
    "            correct_ctr+=1\n",
    "    score=correct_ctr*100/difference.size\n",
    "    print('Score='+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing DataFrame \"data\" into \"d_train\" (60%) and \"d_test\" (40%)\n",
    "divider = np.random.rand(len(data)) < 0.70\n",
    "d_train=data[divider]\n",
    "d_test=data[~divider]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing d_train into data and labels/targets\n",
    "d_train_y=d_train['Type']\n",
    "d_train_X=d_train.drop(['Type'],axis=1)\n",
    "\n",
    "# Dividing d_train into data and labels/targets\n",
    "d_test_y=d_test['Type']\n",
    "d_test_X=d_test.drop(['Type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Iteration 0: [0.17475562 0.53161274 0.18776152 0.59388799]\nIteration 1: [0.22175562 0.56361274 0.20076152 0.59588799]\nIteration 2: [0.26775562 0.59461274 0.21576152 0.59788799]\nIteration 3: [0.31775562 0.63061274 0.22976152 0.59988799]\nIteration 4: [0.37175562 0.66961274 0.24676152 0.60388799]\nIteration 5: [0.41775562 0.70361274 0.26076152 0.60688799]\nIteration 6: [0.46775562 0.73761274 0.27576152 0.60888799]\nIteration 7: [0.51175562 0.76661274 0.28976152 0.61088799]\nIteration 8: [0.56075562 0.79761274 0.30476152 0.61188799]\nIteration 9: [0.60875562 0.82761274 0.31876152 0.61288799]\nIteration 10: [0.66675562 0.86761274 0.33076152 0.61488799]\nIteration 11: [0.72375562 0.91161274 0.34576152 0.61888799]\nIteration 12: [0.77775562 0.95061274 0.35876152 0.62288799]\nIteration 13: [0.82875562 0.98561274 0.37276152 0.62588799]\nIteration 14: [0.88575562 1.02361274 0.38976152 0.62888799]\nIteration 15: [0.93675562 1.06161274 0.40476152 0.63188799]\nIteration 16: [0.98775562 1.09861274 0.41976152 0.63588799]\nIteration 17: [1.03375562 1.13461274 0.42976152 0.63788799]\nIteration 18: [1.08475562 1.16761274 0.44676152 0.64288799]\nIteration 19: [1.13475562 1.19761274 0.46276152 0.64488799]\nIteration 20: [1.18475562 1.23161274 0.47876152 0.64888799]\nIteration 21: [1.23675562 1.26661274 0.49376152 0.65088799]\nIteration 22: [1.28375562 1.29861274 0.50976152 0.65288799]\nIteration 23: [1.33175562 1.32961274 0.52576152 0.65488799]\nIteration 24: [1.38075562 1.36061274 0.54076152 0.65588799]\nIteration 25: [1.42475562 1.39061274 0.55376152 0.65788799]\nIteration 26: [1.47575562 1.42461274 0.56876152 0.65988799]\nIteration 27: [1.52575562 1.45961274 0.58176152 0.66288799]\nIteration 28: [1.57675562 1.49761274 0.60076152 0.66688799]\nIteration 29: [1.62775562 1.53561274 0.61676152 0.66888799]\nIteration 30: [1.67775562 1.56861274 0.63076152 0.67088799]\nIteration 31: [1.81775562 1.63261274 0.72476152 0.69888799]\nIteration 32: [1.94575562 1.69661274 0.81476152 0.72888799]\nIteration 33: [2.08375562 1.75861274 0.91276152 0.75888799]\nIteration 34: [2.19375562 1.80461274 0.99276152 0.78488799]\nIteration 35: [2.31975562 1.87061274 1.08676152 0.81688799]\nIteration 36: [2.41775562 1.91861274 1.15276152 0.83688799]\nIteration 37: [2.54975562 1.97661274 1.24476152 0.86288799]\nIteration 38: [2.65375562 2.03061274 1.32276152 0.89088799]\nIteration 39: [2.77175562 2.09061274 1.40676152 0.92088799]\nIteration 40: [2.89175562 2.13461274 1.48676152 0.94088799]\nIteration 41: [3.00375562 2.19261274 1.55876152 0.96688799]\nIteration 42: [3.13775562 2.25461274 1.64676152 0.99488799]\nIteration 43: [3.24975562 2.31461274 1.73676152 1.02488799]\nIteration 44: [3.36575562 2.36861274 1.81876152 1.04488799]\nIteration 45: [3.48975562 2.41261274 1.90876152 1.07488799]\nIteration 46: [3.61575562 2.46261274 2.00676152 1.10488799]\nIteration 47: [3.74375562 2.52061274 2.09276152 1.13088799]\nIteration 48: [3.87575562 2.58061274 2.18076152 1.15888799]\nIteration 49: [4.00975562 2.64061274 2.28076152 1.19288799]\nIteration 50: [4.12375562 2.69261274 2.35076152 1.21288799]\nIteration 51: [4.23375562 2.74061274 2.42676152 1.23488799]\nIteration 52: [4.34375562 2.78861274 2.50076152 1.25488799]\nIteration 53: [4.45975562 2.84261274 2.57876152 1.27888799]\nIteration 54: [4.57975562 2.89661274 2.68076152 1.31088799]\nIteration 55: [4.68775562 2.95661274 2.77076152 1.34088799]\nIteration 56: [4.81375562 3.00261274 2.85876152 1.36688799]\nIteration 57: [4.92575562 3.06261274 2.94076152 1.39288799]\nIteration 58: [5.03575562 3.11461274 3.02876152 1.41688799]\nIteration 59: [5.15775562 3.17461274 3.12076152 1.44488799]\nIteration 60: [5.27375562 3.22661274 3.20076152 1.46888799]\nIteration 61: [5.37375562 3.27261274 3.26676152 1.48888799]\nIteration 62: [5.48575562 3.32661274 3.35076152 1.51488799]\nIteration 63: [5.59975562 3.38661274 3.43476152 1.53888799]\nIteration 64: [5.71375562 3.44461274 3.51876152 1.56488799]\nIteration 65: [5.83775562 3.50261274 3.60476152 1.59088799]\nIteration 66: [5.93975562 3.55261274 3.66476152 1.61288799]\nIteration 67: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 68: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 69: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 70: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 71: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 72: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 73: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 74: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 75: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 76: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 77: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 78: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 79: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 80: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 81: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 82: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 83: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 84: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 85: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 86: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 87: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 88: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 89: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 90: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 91: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 92: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 93: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 94: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 95: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 96: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 97: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 98: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 99: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 100: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 101: [6.05375562 3.60861274 3.74676152 1.63888799]\nIteration 102: [6.05375562 3.60861274 3.74676152 1.63888799]\nDifference: [5.928 3.107 3.573 1.047]\n"
    }
   ],
   "source": [
    "# Learning rate\n",
    "alpha = 0.01\n",
    "\n",
    "# Train\n",
    "weights = perceptron_train(d_train_X, d_train_y, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "result_test=perceptron_test(d_test_X,d_test_y.shape,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Score=60.869565217391305\n"
    }
   ],
   "source": [
    "# Calculate score\n",
    "score(result_test,d_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}